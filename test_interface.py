"""
Interface de Tests para Moralogy Engine
Corre tests sin modificar principal.py

Uso: streamlit run test_interface.py
"""

import streamlit as st
import sys
import os

# Add src to path si existe
if os.path.exists('src'):
    sys.path.insert(0, 'src')

# Import engine directamente
try:
    from moralogy_engine import MoralityEngine, Option, Agent, HarmType
    ENGINE_AVAILABLE = True
except ImportError:
    ENGINE_AVAILABLE = False
    st.error("‚ö†Ô∏è No se pudo importar moralogy_engine.py")

# Page config
st.set_page_config(
    page_title="Moralogy Tests",
    page_icon="üß™",
    layout="wide"
)

st.title("üß™ Moralogy Engine - Test Suite")
st.caption("Tests independientes del framework (no afecta principal.py)")

if not ENGINE_AVAILABLE:
    st.stop()

# ============================================
# TEST DEFINITIONS
# ============================================

def get_test_cases():
    """Define test cases"""
    tests = {}
    
    # Test 1: Trolley Problem
    tests["Trolley Problem"] = {
        "description": "5 personas vs 1 persona - debe elegir salvar a 5",
        "options": [
            Option(
                name="No hacer nada (mueren 5)",
                agents_affected=[Agent(f"Persona {i}") for i in range(1, 6)],
                harm_types=[HarmType.PHYSICAL] * 5,
                harm_intensities=[1.0] * 5
            ),
            Option(
                name="Cambiar v√≠a (muere 1)",
                agents_affected=[Agent("Persona 1")],
                harm_types=[HarmType.PHYSICAL],
                harm_intensities=[1.0]
            )
        ],
        "expected": 1,
        "reason": "Minimiza da√±o total (1 < 5)"
    }
    
    # Test 2: Consentimiento
    tests["Impacto del Consentimiento"] = {
        "description": "Mismo da√±o, una opci√≥n tiene consentimiento",
        "options": [
            Option(
                name="Con consentimiento",
                agents_affected=[Agent("Paciente A")],
                harm_types=[HarmType.PHYSICAL],
                harm_intensities=[0.5],
                has_consent=True
            ),
            Option(
                name="Sin consentimiento",
                agents_affected=[Agent("Paciente B")],
                harm_types=[HarmType.PHYSICAL],
                harm_intensities=[0.5],
                has_consent=False
            )
        ],
        "expected": 0,
        "reason": "Consentimiento reduce peso moral"
    }
    
    # Test 3: Vulnerabilidad
    tests["Escala de Vulnerabilidad"] = {
        "description": "Misma acci√≥n, diferente vulnerabilidad",
        "options": [
            Option(
                name="Da√±ar ni√±o vulnerable",
                agents_affected=[Agent("Ni√±o", vulnerability=1.0)],
                harm_types=[HarmType.PHYSICAL],
                harm_intensities=[0.5]
            ),
            Option(
                name="Da√±ar adulto protegido",
                agents_affected=[Agent("Adulto", vulnerability=0.3)],
                harm_types=[HarmType.PHYSICAL],
                harm_intensities=[0.5]
            )
        ],
        "expected": 1,
        "reason": "Proteger al m√°s vulnerable"
    }
    
    # Test 4: Tipos de da√±o
    tests["Peso de Tipos de Da√±o"] = {
        "description": "Da√±o f√≠sico vs psicol√≥gico",
        "options": [
            Option(
                name="Da√±o f√≠sico",
                agents_affected=[Agent("Persona A")],
                harm_types=[HarmType.PHYSICAL],
                harm_intensities=[0.5]
            ),
            Option(
                name="Da√±o psicol√≥gico",
                agents_affected=[Agent("Persona B")],
                harm_types=[HarmType.PSYCHOLOGICAL],
                harm_intensities=[0.5]
            )
        ],
        "expected": 1,
        "reason": "Da√±o psicol√≥gico pesa menos (0.8 vs 1.0)"
    }
    
    # Test 5: Opci√≥n sin da√±o
    tests["Preferencia por Cero Da√±o"] = {
        "description": "Cuando es posible, elegir no causar da√±o",
        "options": [
            Option(
                name="Causar da√±o moderado",
                agents_affected=[Agent("Persona")],
                harm_types=[HarmType.PHYSICAL],
                harm_intensities=[0.5]
            ),
            Option(
                name="No causar da√±o",
                agents_affected=[],
                harm_types=[],
                harm_intensities=[]
            )
        ],
        "expected": 1,
        "reason": "Cero da√±o siempre preferible"
    }
    
    return tests

def run_test(test_name, test_data):
    """Run single test"""
    engine = MoralityEngine()
    
    try:
        result = engine.evaluate_options(test_data["options"])
        
        passed = result["recommendation_idx"] == test_data["expected"]
        
        return {
            "passed": passed,
            "expected": test_data["expected"],
            "actual": result["recommendation_idx"],
            "confidence": result.get("confidence", 0.0),
            "harm_scores": result["harm_scores"],
            "justification": result["justification"],
            "reason": test_data["reason"]
        }
    except Exception as e:
        return {
            "passed": False,
            "expected": test_data["expected"],
            "actual": -1,
            "confidence": 0.0,
            "harm_scores": [],
            "justification": f"ERROR: {str(e)}",
            "reason": test_data["reason"]
        }

# ============================================
# UI
# ============================================

st.markdown("---")

# Sidebar
with st.sidebar:
    st.header("‚ÑπÔ∏è Informaci√≥n")
    st.markdown("""
    Esta interfaz prueba la l√≥gica del **Moralogy Engine** sin modificar `principal.py`.
    
    **Framework:** [DOI 10.5281/zenodo.18091340](https://doi.org/10.5281/zenodo.18091340)
    
    **Tests disponibles:**
    - Problema del tranv√≠a
    - Impacto del consentimiento
    - Escala de vulnerabilidad
    - Peso de tipos de da√±o
    - Preferencia por cero da√±o
    """)
    
    st.markdown("---")
    st.caption("üîó [Ver principal.py](https://github.com/pipefleurs87-sudo/moralogy-gemini-evaluator)")

# Main content
tab1, tab2 = st.tabs(["üöÄ Ejecutar Tests", "üìñ Documentaci√≥n"])

with tab1:
    
    # Get tests
    test_cases = get_test_cases()
    
    st.header("Tests Autom√°ticos")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        run_all = st.button("‚ñ∂Ô∏è Ejecutar Todos", use_container_width=True, type="primary")
    
    with col2:
        st.info(f"üìä {len(test_cases)} tests disponibles")
    
    # Run all tests
    if run_all:
        st.markdown("---")
        
        results = {}
        progress = st.progress(0)
        status = st.empty()
        
        for i, (name, data) in enumerate(test_cases.items()):
            status.text(f"Ejecutando: {name}...")
            result = run_test(name, data)
            results[name] = result
            progress.progress((i + 1) / len(test_cases))
        
        status.empty()
        progress.empty()
        
        # Summary
        passed = sum(1 for r in results.values() if r["passed"])
        total = len(results)
        
        if passed == total:
            st.success(f"‚úÖ TODOS LOS TESTS PASARON ({passed}/{total})")
        elif passed > 0:
            st.warning(f"‚ö†Ô∏è {passed}/{total} tests pasaron")
        else:
            st.error(f"‚ùå Ning√∫n test pas√≥ (0/{total})")
        
        # Detailed results
        st.markdown("### Resultados Detallados")
        
        for test_name, result in results.items():
            emoji = "‚úÖ" if result["passed"] else "‚ùå"
            
            with st.expander(f"{emoji} {test_name}", expanded=not result["passed"]):
                
                # Status row
                col1, col2, col3 = st.columns(3)
                
                if result["passed"]:
                    col1.success("PAS√ì")
                else:
                    col1.error("FALL√ì")
                
                col2.metric("Confianza", f"{result['confidence']*100:.0f}%")
                col3.info(f"Esperado: Opci√≥n {result['expected']+1}")
                
                # Error details
                if not result["passed"]:
                    st.error(f"""
                    **Discrepancia:**
                    - Esperado: Opci√≥n {result['expected']+1}
                    - Obtenido: Opci√≥n {result['actual']+1}
                    
                    **Raz√≥n esperada:** {result['reason']}
                    """)
                
                # Harm scores
                if result["harm_scores"]:
                    st.markdown("**Puntajes de Da√±o:**")
                    
                    for i, score in enumerate(result["harm_scores"]):
                        is_chosen = (i == result['actual'])
                        color = "üü¢" if is_chosen else "üî¥"
                        st.write(f"{color} Opci√≥n {i+1}: {score.total_harm:.3f} ({score.severity})")
                    
                    # Chart
                    import plotly.graph_objects as go
                    
                    harm_values = [s.total_harm for s in result["harm_scores"]]
                    colors = ['green' if i == result['actual'] else 'red' 
                             for i in range(len(harm_values))]
                    
                    fig = go.Figure(data=[
                        go.Bar(
                            x=[f"Opci√≥n {i+1}" for i in range(len(harm_values))],
                            y=harm_values,
                            marker_color=colors
                        )
                    ])
                    fig.update_layout(
                        title="Comparaci√≥n de Da√±o",
                        yaxis_title="Puntaje de Da√±o",
                        showlegend=False,
                        height=300
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                # Full justification
                st.markdown("**Justificaci√≥n Completa:**")
                st.code(result["justification"], language="text")
    
    # Individual test runner
    st.markdown("---")
    st.header("Test Individual")
    
    selected = st.selectbox(
        "Selecciona un test:",
        ["Elige un test..."] + list(test_cases.keys())
    )
    
    if selected != "Elige un test...":
        test_data = test_cases[selected]
        
        st.info(f"**üìù Descripci√≥n:** {test_data['description']}")
        st.caption(f"**Raz√≥n esperada:** {test_data['reason']}")
        
        if st.button(f"‚ñ∂Ô∏è Ejecutar '{selected}'", use_container_width=True):
            
            with st.spinner("Ejecutando..."):
                result = run_test(selected, test_data)
            
            # Result
            if result["passed"]:
                st.success("‚úÖ TEST PAS√ì")
            else:
                st.error("‚ùå TEST FALL√ì")
            
            # Details
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**M√©tricas:**")
                for i, score in enumerate(result["harm_scores"]):
                    st.metric(
                        f"Opci√≥n {i+1}",
                        f"{score.total_harm:.3f}",
                        f"{score.severity}"
                    )
            
            with col2:
                st.markdown("**Comparaci√≥n:**")
                if result["harm_scores"]:
                    harm_data = {
                        f"Opci√≥n {i+1}": s.total_harm 
                        for i, s in enumerate(result["harm_scores"])
                    }
                    st.bar_chart(harm_data)
            
            st.markdown("**An√°lisis Completo:**")
            st.code(result["justification"], language="text")

with tab2:
    st.header("üìñ Documentaci√≥n de Tests")
    
    st.markdown("""
    ### Prop√≥sito
    
    Esta interfaz verifica que el **Moralogy Engine** tome decisiones l√≥gicamente consistentes.
    
    ### Tests Implementados
    
    1. **Problema del Tranv√≠a**
       - Verifica que el sistema elija la opci√≥n con menor da√±o total
       - 5 muertes vs 1 muerte ‚Üí debe elegir 1 muerte
    
    2. **Impacto del Consentimiento**
       - Verifica que el consentimiento reduzca el peso moral del da√±o
       - Mismo da√±o, una opci√≥n consentida ‚Üí debe preferir consentida
    
    3. **Escala de Vulnerabilidad**
       - Verifica que la vulnerabilidad amplifique el da√±o
       - Mismo da√±o, diferentes vulnerabilidades ‚Üí proteger m√°s vulnerable
    
    4. **Peso de Tipos de Da√±o**
       - Verifica que diferentes tipos de da√±o tengan pesos correctos
       - F√≠sico (1.0) > Psicol√≥gico (0.8)
    
    5. **Preferencia por Cero Da√±o**
       - Verifica que cuando hay opci√≥n sin da√±o, se elija
       - Da√±o moderado vs cero da√±o ‚Üí elegir cero
    
    ### Interpretaci√≥n de Resultados
    
    - ‚úÖ **PAS√ì**: El motor tom√≥ la decisi√≥n esperada
    - ‚ùå **FALL√ì**: El motor tom√≥ decisi√≥n diferente (revisar l√≥gica)
    - **Confianza**: Qu√© tan clara es la elecci√≥n (0-100%)
    
    ### Framework Completo
    
    Para m√°s detalles sobre el framework Moralogy:
    - **Paper:** [DOI: 10.5281/zenodo.18091340](https://doi.org/10.5281/zenodo.18091340)
    - **Repo:** [GitHub](https://github.com/pipefleurs87-sudo/moralogy-gemini-evaluator)
    """)

# Footer
st.markdown("---")
st.caption("üß™ Test Interface | Moralogy Framework v1.0 | No modifica principal.py")
```

**Commit con mensaje:**
```
Added standalone test interface (test_interface.py)
- Runs tests independently from principal.py
- Visual test runner with Streamlit
- 5 comprehensive test cases
